{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn import preprocessing\n",
    "from collections import deque\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,LSTM,CuDNNLSTM,BatchNormalization\n",
    "from tensorflow.keras.callbacks import TensorBoard,ModelCheckpoint\n",
    "\n",
    "SEQ_LEN=60\n",
    "FUTURE_PERIOD_PREDICT=3\n",
    "RATIO_TO_PREDICT=\"LTC-USD\"\n",
    "EPOCHS=10\n",
    "BATCH_SIZE=64\n",
    "NAME=f\"{SEQ_LEN}-SEQ-{FUTURE_PERIOD_PREDICT}-PRED-{int(time.time())}\"\n",
    "def classify(current,future):\n",
    "    if float(future)>float(current):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "def preprocess(df):\n",
    "    df.drop('future',1)\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if col!=\"target\":\n",
    "            df[col]=df[col].pct_change()\n",
    "            df.dropna(inplace=True)\n",
    "            df[col]=preprocessing.scale(df[col].values)\n",
    "    df.dropna(inplace=True)\n",
    "    \n",
    "    sequential_data=[]\n",
    "    prev_days=deque(maxlen=SEQ_LEN)\n",
    "    \n",
    "    for i in df.values:\n",
    "        prev_days.append([n for n in i[:-1]])\n",
    "        if len(prev_days)==SEQ_LEN:\n",
    "            sequential_data.append([np.array(prev_days),i[-1]])\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    buys=[]\n",
    "    sells=[]\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        if target==0:\n",
    "            sells.append([seq,target])\n",
    "        elif target==1:\n",
    "            buys.append([seq,target])\n",
    "    random.shuffle(buys)\n",
    "    random.shuffle(sells)\n",
    "    \n",
    "    lower=min(len(buys),len(sells))\n",
    "    \n",
    "    buys=buys[:lower]\n",
    "    sells=sells[:lower]\n",
    "    \n",
    "    sequential_data=buys+sells\n",
    "    random.shuffle(sequential_data)\n",
    "    \n",
    "    X=[]\n",
    "    y=[]\n",
    "    \n",
    "    for seq,target in sequential_data:\n",
    "        X.append(seq)\n",
    "        y.append(target)\n",
    "    return np.array(X),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         time        low       high       open      close      volumn\n",
      "0  1528968660  96.580002  96.589996  96.589996  96.580002    9.647200\n",
      "1  1528968720  96.449997  96.669998  96.589996  96.660004  314.387024\n",
      "2  1528968780  96.470001  96.570000  96.570000  96.570000   77.129799\n",
      "3  1528968840  96.449997  96.570000  96.570000  96.500000    7.216067\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"LTC-USD.csv\",names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volumn\"])\n",
    "print(df.head(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BTC-USD_close  BTC-USD_volumn\n",
      "time                                     \n",
      "1528968660    6489.549805        0.587100\n",
      "1528968720    6487.379883        7.706374\n",
      "1528968780    6479.410156        3.088252\n",
      "1528968840    6479.410156        1.404100\n",
      "            BTC-USD_close  BTC-USD_volumn  LTC-USD_close  LTC-USD_volumn\n",
      "time                                                                    \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200\n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024\n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799\n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067\n",
      "            BTC-USD_close  BTC-USD_volumn  LTC-USD_close  LTC-USD_volumn  \\\n",
      "time                                                                       \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "\n",
      "            ETH-USD_close  ETH-USD_volumn  \n",
      "time                                       \n",
      "1528968660            NaN             NaN  \n",
      "1528968720      486.01001       26.019083  \n",
      "1528968780      486.00000        8.449400  \n",
      "1528968840      485.75000       26.994646  \n",
      "            BTC-USD_close  BTC-USD_volumn  LTC-USD_close  LTC-USD_volumn  \\\n",
      "time                                                                       \n",
      "1528968660    6489.549805        0.587100      96.580002        9.647200   \n",
      "1528968720    6487.379883        7.706374      96.660004      314.387024   \n",
      "1528968780    6479.410156        3.088252      96.570000       77.129799   \n",
      "1528968840    6479.410156        1.404100      96.500000        7.216067   \n",
      "\n",
      "            ETH-USD_close  ETH-USD_volumn  BCH-USD_close  BCH-USD_volumn  \n",
      "time                                                                      \n",
      "1528968660            NaN             NaN     871.719971        5.675361  \n",
      "1528968720      486.01001       26.019083     870.859985       26.856577  \n",
      "1528968780      486.00000        8.449400     870.099976        1.124300  \n",
      "1528968840      485.75000       26.994646     870.789978        1.749862  \n"
     ]
    }
   ],
   "source": [
    "main_df=pd.DataFrame()\n",
    "\n",
    "ratios=[\"BTC-USD\",\"LTC-USD\",\"ETH-USD\",\"BCH-USD\"]\n",
    "for ratio in ratios:\n",
    "    dataset=f\"{ratio}.csv\"\n",
    "    df=pd.read_csv(dataset,names=[\"time\",\"low\",\"high\",\"open\",\"close\",\"volumn\"])\n",
    "    #print(df.head(3))\n",
    "    df.rename(columns={\"close\":f\"{ratio}_close\",\"volumn\":f\"{ratio}_volumn\"},inplace=True)\n",
    "    df.set_index(\"time\",inplace=True)\n",
    "    df=df[[f\"{ratio}_close\",f\"{ratio}_volumn\"]]\n",
    "    \n",
    "    if len(main_df)==0:\n",
    "        main_df=df\n",
    "    else:\n",
    "        main_df=main_df.join(df)\n",
    "    print(main_df.head(4))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future\n",
      "time                                \n",
      "1528968660      96.580002  96.500000\n",
      "1528968720      96.660004  96.389999\n",
      "1528968780      96.570000  96.519997\n"
     ]
    }
   ],
   "source": [
    "main_df['future']=main_df[f\"{RATIO_TO_PREDICT}_close\"].shift(-FUTURE_PERIOD_PREDICT)\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            LTC-USD_close     future  target\n",
      "time                                        \n",
      "1528968660      96.580002  96.500000       0\n",
      "1528968720      96.660004  96.389999       0\n",
      "1528968780      96.570000  96.519997       0\n"
     ]
    }
   ],
   "source": [
    "main_df['target']=list(map(classify,main_df[f\"{RATIO_TO_PREDICT}_close\"],main_df[\"future\"]))\n",
    "print(main_df[[f\"{RATIO_TO_PREDICT}_close\",\"future\",\"target\"]].head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "times=sorted(main_df.index.values)\n",
    "last=times[-int(0.05*len(times))]\n",
    "\n",
    "validation_main_df=main_df[(main_df.index>=last)]\n",
    "main_df=main_df[(main_df.index<last)]\n",
    "\n",
    "train_X,train_y=preprocess(main_df)\n",
    "validation_X,validation_y=preprocess(validation_main_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 69186 samples, validate on 3056 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "2 root error(s) found.\n  (0) Invalid argument: Incompatible shapes: [64,60] vs. [64]\n\t [[{{node metrics_2/acc/Equal}}]]\n\t [[loss_1/mul/_521]]\n  (1) Invalid argument: Incompatible shapes: [64,60] vs. [64]\n\t [[{{node metrics_2/acc/Equal}}]]\n0 successful operations.\n0 derived errors ignored.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-84d18a2ef671>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m )\n",
      "\u001b[1;32mc:\\users\\huang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    778\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m           \u001b[0mvalidation_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m           steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mc:\\users\\huang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\huang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3291\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3292\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3293\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3294\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[1;32mc:\\users\\huang\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[0;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1458\u001b[1;33m                                                run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: 2 root error(s) found.\n  (0) Invalid argument: Incompatible shapes: [64,60] vs. [64]\n\t [[{{node metrics_2/acc/Equal}}]]\n\t [[loss_1/mul/_521]]\n  (1) Invalid argument: Incompatible shapes: [64,60] vs. [64]\n\t [[{{node metrics_2/acc/Equal}}]]\n0 successful operations.\n0 derived errors ignored."
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_X.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_X.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(CuDNNLSTM(128,input_shape=(train_X.shape[1:]),return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(32,activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(2,activation=\"softmax\"))\n",
    "\n",
    "opt=tf.keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='sparse_categorical_crossentropy',optimizer=opt,metrics=['accuracy'])\n",
    "\n",
    "tensorboard=TensorBoard(log_dir=f'logs/{NAME}')\n",
    "\n",
    "filepath='RNN_FINAL-{epoch:02d}-{val_acc:.3f}'\n",
    "checkpoint=ModelCheckpoint(\"models/{}.model\".format(filepath,monitor=\"val_acc\",verbose=1,save_best_only=True,mode='max'))\n",
    "\n",
    "history=model.fit(\n",
    "    train_X,train_y,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=(validation_X,validation_y)\n",
    "    \n",
    ")\n",
    "#callbacks=[tensorboard,checkpoint]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
